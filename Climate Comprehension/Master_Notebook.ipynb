{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Corpus to Conclusions:</h1></center>\n",
    "<center><h4>Integrating Full NLP Pipeline Techniques For Climate Change Text Analytics</h4></center>\n",
    "\n",
    "By: **Elijah Taber**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Elijah Taber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Elijah\n",
      "[nltk_data]     Taber\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Elijah\n",
      "[nltk_data]     Taber\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Elijah Taber\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import warnings\n",
    "import umap\n",
    "import sqlite3\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import tensorflow_hub as hub\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# NLP\n",
    "import transformers\n",
    "import spacy\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from bertopic import BERTopic\n",
    "from transformers import (\n",
    "    RobertaTokenizer, \n",
    "    RobertaModel, \n",
    "    BartTokenizer, \n",
    "    BartModel\n",
    ")\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Custom Data Processors\n",
    "from src.normalizer import TextNormalizer\n",
    "from src.pdf_processor import pdf_text_extractor\n",
    "\n",
    "#########################################################################################\n",
    "#                           Text Classification Network (C4NN)                          #\n",
    "#########################################################################################\n",
    "from nlp.\\\n",
    "        text_classification_network.\\\n",
    "            classification_cnn import (\n",
    "                CNNHyperModel as C4NN, \n",
    "                BayesianTuner\n",
    ")\n",
    "from nlp.\\\n",
    "        text_classification_network.\\\n",
    "            classification_setup import (\n",
    "                LexicalTokenizer, \n",
    "                EmbeddingMatrix\n",
    ")\n",
    "from nlp.\\\n",
    "        text_classification_network.\\\n",
    "            classification_visualizer import (\n",
    "                SphericalMap\n",
    ")\n",
    "from nlp.\\\n",
    "        text_classification_network.\\\n",
    "            classification_evaluator import (\n",
    "                C4NNEvaluator\n",
    ")\n",
    "\n",
    "#########################################################################################\n",
    "#                            Topic Transformer (CLIMATopic)                             #\n",
    "#########################################################################################\n",
    "from nlp.\\\n",
    "        topic_model.\\\n",
    "            topic_transformer import (\n",
    "                CLIMATopic\n",
    ")\n",
    "from nlp.\\\n",
    "        topic_model.\\\n",
    "            tm_config import (\n",
    "                BERTopicConfig, \n",
    "                SaveConfig, \n",
    "                VisualizationConfig,\n",
    "                EvaluationConfig\n",
    ")\n",
    "from nlp.\\\n",
    "        topic_model.\\\n",
    "            topic_visualizations import (\n",
    "                visualize_umap,\n",
    "                visualize_topics, \n",
    "                visualize_heatmap, \n",
    "                visualize_document_datamap\n",
    ")\n",
    "from nlp.\\\n",
    "        topic_model.\\\n",
    "            bertopic_setup import (\n",
    "                create_umap\n",
    ")\n",
    "from nlp.\\\n",
    "        topic_model.\\\n",
    "            tm_evaluator import (\n",
    "                evaluate_topic_models\n",
    ")\n",
    "\n",
    "#########################################################################################\n",
    "#                      Hybrid Summarization Engine (CLIMATEBart/C3)                     #\n",
    "#########################################################################################\n",
    "from nlp.\\\n",
    "        hybrid_text_summarization_engine.\\\n",
    "            ts_corpus_cleaner import (\n",
    "                preprocess_text, # deployment\n",
    "                preprocess_dataframe # training\n",
    ")\n",
    "from nlp.\\\n",
    "        hybrid_text_summarization_engine.\\\n",
    "            ts_feature_engineering import (\n",
    "                feature_engineering_pipeline, # deployment\n",
    "                feature_engineering_pipeline_dataframe # training\n",
    ")\n",
    "from nlp.\\\n",
    "        hybrid_text_summarization_engine.\\\n",
    "            ts_feature_visualizations import (\n",
    "                visualize_tfidf,\n",
    "                visualize_embeddings,\n",
    "                visualize_topics,\n",
    "                visualize_named_entities,\n",
    "                visualize_keywords\n",
    ")\n",
    "from nlp.\\\n",
    "        hybrid_text_summarization_engine.\\\n",
    "            climate_corpus_condenser import (\n",
    "                ClimateExtractiveModel, \n",
    "                CLIMATEBart, \n",
    "                ClimateCorpusCondenser as C3\n",
    ")\n",
    "from nlp.\\\n",
    "        hybrid_text_summarization_engine.\\\n",
    "            ts_evaluator import (\n",
    "                BARTevaluator\n",
    ")\n",
    "\n",
    "#########################################################################################\n",
    "#                          Sentiment Analysis Network (RoBi)                            #\n",
    "#########################################################################################\n",
    "from nlp.\\\n",
    "        sentiment_analysis_network.\\\n",
    "            hybrid_sentiment_network import (\n",
    "                RoBi, \n",
    "                SlidingWindow, \n",
    "                train_RoBi, \n",
    "                save_RoBi, \n",
    "                load_RoBi, \n",
    "                predict_sentiment\n",
    ")\n",
    "from nlp.\\\n",
    "        sentiment_analysis_network.\\\n",
    "            robi_config import (\n",
    "                SlidingWindowConfig, \n",
    "                RoBiConfig, \n",
    "                TrainConfig, \n",
    "                SaveLoadConfig, \n",
    "                PredictConfig,\n",
    "                RoBiEvaluationConfig\n",
    ")\n",
    "from nlp.\\\n",
    "        sentiment_analysis_network.\\\n",
    "            robi_evaluator import (\n",
    "                evaluate_robi, \n",
    "                evaluate_roberta, \n",
    "                evaluate_and_visualize\n",
    ")\n",
    "\n",
    "# Set random seeds for reproducibility, each package must be individually addressed to lock in randomized settings under the hood\n",
    "random.seed(10) # standard python\n",
    "np.random.seed(10) # numpy\n",
    "tf.random.set_seed(10) # tensorflow\n",
    "transformers.set_seed(10) # transformers\n",
    "torch.manual_seed(10) # torch\n",
    "if torch.cuda.is_available(): # GPU\n",
    "    torch.cuda.manual_seed_all(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training & Evaluation Data From SQLite Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('tagged_climate_corpuses.csv')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "print(f\"Connected to SQLite database: {'tagged_climate_corpuses.csv'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"\"\"\n",
    "SELECT name FROM sqlite_master \n",
    "WHERE type='table';\n",
    "\"\"\")\n",
    "\n",
    "tables = cursor.fetchall()\n",
    "for table in tables:\n",
    "    print(table[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataframe(conn):\n",
    "    query = \"SELECT * FROM TrainingData;\"\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    print(f\"Loaded Training DataFrame with {len(df)} records.\")\n",
    "    return df\n",
    "\n",
    "training_corpus_df = load_dataframe(conn)\n",
    "training_corpus_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataframe(conn):\n",
    "    query = \"SELECT * FROM EvaluationData;\"\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    print(f\"Loaded Evaluation DataFrame with {len(df)} records.\")\n",
    "    return df\n",
    "\n",
    "evaluation_corpus_df = load_dataframe(conn)\n",
    "evaluation_corpus_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the database connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the TCNormalizer class\n",
    "normalizer = TextNormalizer()\n",
    "\n",
    "# Normalize the dataframe\n",
    "normalized_df = normalizer.normalize_dataframe(training_corpus_df, 'corpus')\n",
    "normalized_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating The Full Token Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the corpus column as a list of strings\n",
    "corpus_list = normalized_df['corpus'].tolist()\n",
    "\n",
    "# Calculate the total token count\n",
    "corpus_length = sum(len(document.split()) for document in corpus_list)\n",
    "\n",
    "print(f\"Total tokens in normalized corpus: {corpus_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Climate Change Classification using a Convolutional Neural Network (C4NN)</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3D Classification Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sherical_visualizer = SphericalMap()\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "\n",
    "X = vectorizer.fit_transform(normalized_df['corpus']).toarray()\n",
    "\n",
    "classification = normalized_df['classification'].tolist()\n",
    "topic = normalized_df['topic'].tolist()\n",
    "\n",
    "sherical_visualizer.create_visualization(X, classification, topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training The Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Universal Sentence Encoder (USE)\n",
    "Google's TensorFlow Universal Sentence Encoder is a pre-trained model that converts text into fixed-length numerical vectors, allowing neural networks to understand the semantic meaning of sentences. It is crucial in NLP models as it provides a way to represent variable-length text inputs as fixed-size embeddings, simplifying the task of processing text for downstream tasks like classification, clustering, or semantic similarity. In the tokenization phase of an NLP pipeline, the Universal Sentence Encoder is used to convert raw text into vector representations, which can then be fed into a neural network for further processing. This enables the network to learn from the semantic meanings of sentences, rather than just their individual words, which results in a more accurate and context-aware language understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the Universal Sentence Encoder model and save it locally\n",
    "use_model = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "tf.saved_model.save(use_model, \"use_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize & Fit the Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = LexicalTokenizer(use_model_path='use_model')\n",
    "\n",
    "# Train the tokenizer on the normalized dataframe\n",
    "tokenizer.fit(\n",
    "    normalized_df, \n",
    "    text_column='corpus',\n",
    "    topic_column='topic',\n",
    "    classification_column='classification', \n",
    "    sentiment_column='sentiment'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save The Trained Tokenizer & Encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save_tokenizer('tokenizer.pkl')\n",
    "\n",
    "with open('topic_label_encoder.pkl', 'wb') as handle:\n",
    "    pickle.dump(tokenizer.label_encoders['topic'], handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('classification_label_encoder.pkl', 'wb') as handle:\n",
    "    pickle.dump(tokenizer.label_encoders['classification'], handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('sentiment_label_encoder.pkl', 'wb') as handle:\n",
    "    pickle.dump(tokenizer.label_encoders['sentiment'], handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 100 Dimensional Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the embedding matrix creator with the trained tokenizer\n",
    "embedding_matrix_creator = EmbeddingMatrix(\n",
    "    tokenizer, # vocabulary created by the tokenizer\n",
    "    embedding_dim = 100, # dimensions\n",
    "    glove_path = 'GloVe/glove.6B.100d.txt' # pre-trained embeddings with 6 billion tokens\n",
    ")\n",
    "\n",
    "# Create the embedding matrix\n",
    "embedding_matrix = embedding_matrix_creator.get_embedding_matrix()\n",
    "for i in range(5):\n",
    "    print(f\"Row {i}: {embedding_matrix[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('embedding_matrix.npy', embedding_matrix)\n",
    "print(\"Embedding matrix shape:\", embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize & Encode The Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = tokenizer.preprocess_dataframe(\n",
    "    normalized_df, \n",
    "    text_column='corpus', # pad\n",
    "    topic_column='topic', # encode\n",
    "    classification_column='classification', # encode\n",
    "    sentiment_column='sentiment', # encode\n",
    "    summary_column='summary' # pad\n",
    ")\n",
    "\n",
    "print(\"Text Embeddings Shape:\", processed_data['text_embeddings'].shape)\n",
    "print(\"Summary Embeddings Shape:\", processed_data['summary_embeddings'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenizer.pkl', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "\n",
    "embedding_matrix = np.load('embedding_matrix.npy')\n",
    "\n",
    "# Extract necessary data for training\n",
    "X = processed_data['text']  # extract the padded text sequences\n",
    "y = processed_data['classification']  # extract the encoded classification labels\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=0.2, \n",
    "    random_state=10\n",
    ")\n",
    "\n",
    "# Once the training data is defined, further split the training data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    test_size=0.2, \n",
    "    random_state=10\n",
    ")\n",
    "\n",
    "max_sequence_length = X.shape[1]\n",
    "num_classes = len(np.unique(y))\n",
    "\n",
    "print(f\"Max sequence length: {max_sequence_length}\")\n",
    "print(f\"Number of classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for GPU\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CNNHyperModel\n",
    "c4nn_hypermodel = C4NN(\n",
    "    embedding_matrix, \n",
    "    max_sequence_length,\n",
    "    num_classes\n",
    ")\n",
    "\n",
    "# Create the BayesianTuner\n",
    "tuner = BayesianTuner(hypermodel=c4nn_hypermodel.architect)\n",
    "\n",
    "# Search for the best model\n",
    "tuner.search(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    X_val, \n",
    "    y_val,\n",
    ")\n",
    "\n",
    "# Extract and save the best classification model\n",
    "best_model = tuner.get_best_model()\n",
    "history = tuner.get_history()\n",
    "tuner.save_best_model(best_model, path='best_c4nn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = BayesianTuner.load_best_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = C4NNEvaluator()\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = evaluator.evaluate_model(X_test, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Get predictions\n",
    "y_pred_proba = evaluator.get_predictions(X_test)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "class_names = ['Research Article', 'News Article', 'Opinion Piece', 'Blog Post', 'Review Article', \n",
    "               'Policy Report', 'Educational Material', 'Data Report', 'Interviews and Profiles']\n",
    "\n",
    "# Plot confusion matrix\n",
    "evaluator.plot_confusion_matrix(y_test, y_pred, class_names)\n",
    "\n",
    "# Plot ROC curve\n",
    "evaluator.plot_roc_curve(y_test, y_pred_proba, class_names)\n",
    "\n",
    "# Plot precision, recall, and F1-score\n",
    "evaluator.plot_precision_recall_f1(y_test, y_pred, class_names)\n",
    "\n",
    "evaluator.plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Topic Model</h1></center>\n",
    "\n",
    "## CLIMATopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations\n",
    "bertopic_config = BERTopicConfig()\n",
    "save_config = SaveConfig()\n",
    "vis_config = VisualizationConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = normalized_df['corpus'].tolist()\n",
    "\n",
    "# Initialize CLIMATopic\n",
    "climatopic_model = CLIMATopic(bertopic_config, save_config)\n",
    "climatopic_model.to_device(device)\n",
    "\n",
    "# Fit the model\n",
    "topics, probs = climatopic_model.fit(docs)\n",
    "\n",
    "print(\"Topics:\", topics)\n",
    "print(\"\\nProbabilities:\", probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "climatopic_model.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "climatopic_model.load(save_config.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get topic information\n",
    "topic_info = climatopic_model.topic_model.get_topic_info()\n",
    "topic_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = climatopic_model.embedding_model.encode(docs, show_progress_bar=True)\n",
    "umap_model = create_umap()\n",
    "\n",
    "visualize_umap(embeddings, umap_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "climatopic_model.topic_model.visualize_term_rank(log_scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of topics\n",
    "visualize_topics(climatopic_model.topic_model)\n",
    "\n",
    "# Visualization of heatmap\n",
    "visualize_heatmap(climatopic_model.topic_model)\n",
    "\n",
    "# Visualization of document datamap\n",
    "visualize_document_datamap(climatopic_model.topic_model, docs, embeddings=embeddings, width=vis_config.width,\n",
    "                           height=vis_config.height, title=vis_config.title, sub_title=vis_config.sub_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get representations for a specific topic\n",
    "topic_representation = climatopic_model.topic_model.get_topic(1, full=True)\n",
    "print(topic_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict topics for the new article\n",
    "new_topics, new_probs = climatopic_model.topic_model.transform(new_article)\n",
    "\n",
    "print(\"Predicted Topics:\", new_topics)\n",
    "print(\"Topic Probabilities:\", new_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained CLIMATopic model\n",
    "climatopic_config = BERTopicConfig()\n",
    "save_config = SaveConfig()\n",
    "climatopic = CLIMATopic(climatopic_config, save_config)\n",
    "climatopic.load(\"path/to/your/saved/climatopic/model\")\n",
    "\n",
    "bertopic = BERTopic()\n",
    "\n",
    "# Load your evaluation articles (replace with your actual data loading code)\n",
    "with open('path/to/your/evaluation/articles.txt', 'r') as f:\n",
    "    evaluation_articles = f.readlines()\n",
    "\n",
    "# Load your single complex document (replace with your actual data loading code)\n",
    "with open('path/to/your/complex/document.txt', 'r') as f:\n",
    "    complex_document = f.read()\n",
    "\n",
    "# Generate topics for CLIMATopic (using transform)\n",
    "climatopic_topics, climatopic_probs = climatopic.topic_model.transform(evaluation_articles)\n",
    "\n",
    "# Fit and transform the standard BERTopic model\n",
    "bertopic_topics, bertopic_probs = bertopic.fit_transform(evaluation_articles)\n",
    "\n",
    "# Set up the evaluation configuration\n",
    "eval_config = EvaluationConfig()\n",
    "\n",
    "# Evaluate both models\n",
    "results = evaluate_topic_models(\n",
    "    climatopic.topic_model,\n",
    "    bertopic,\n",
    "    evaluation_articles,\n",
    "    complex_document,\n",
    "    eval_config\n",
    ")\n",
    "\n",
    "# The results, including visualizations, will be displayed automatically\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Hybrid Text Summarization Engine</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An In-Depth Analysis At Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text from PDF to get a raw and very messy corpus\n",
    "raw_corpus = pdf_text_extractor(\n",
    "    \"hybrid_text_summarization_engine/complex_pdf/IPCC_AR6_WGIII_TechnicalSummary.pdf\", \n",
    "    start_page=7, \n",
    "    end_page=101\n",
    ")\n",
    "raw_corpus[:500] # first 500 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_corpus = preprocess_text(raw_corpus)\n",
    "cleaned_corpus[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Doc object by applying the NLP model to the cleaned corpus\n",
    "doc = nlp(cleaned_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sentences from the Doc object and store them in a list\n",
    "sentences = [sent.text for sent in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform feature engineering on the extracted sentences\n",
    "features = feature_engineering_pipeline(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Term Frequency-Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top 10 TF-IDF Scores:\")\n",
    "counter = 0\n",
    "for term, score in features['tfidf'].items():\n",
    "    print(f\"{term}: {score}\")\n",
    "    counter += 1\n",
    "    if counter == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_tfidf(features['tfidf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentence Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First 10 Sentence Embeddings:\")\n",
    "for index, embedding in enumerate(features['embeddings']):\n",
    "    print(embedding)\n",
    "    if index == 9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_embeddings(features['embeddings'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LDA Topics:\")\n",
    "print(features['topics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_topics(features['topics'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First 10 Named Entities:\")\n",
    "for index, entity in enumerate(features['entities']):\n",
    "    print(f\"Entity: {entity[0]}, Type: {entity[1]}\")\n",
    "    if index == 9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_named_entities(features['entities'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First 10 Keywords:\")\n",
    "for index, keyword in enumerate(features['keywords']):\n",
    "    print(keyword)\n",
    "    if index == 9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_keywords(features['keywords'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Climate Corpus Condenser (C3)\n",
    "#### A Climate Change Tuned BART Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Corpus cleaning\n",
    "cleaned_df = preprocess_dataframe(training_corpus_df, 'corpus')\n",
    "\n",
    "# 2. Feature engineering\n",
    "features = feature_engineering_pipeline_dataframe(cleaned_df, 'corpus')\n",
    "\n",
    "articles = cleaned_df['corpus'].tolist()\n",
    "summaries = cleaned_df['summary'].tolist()\n",
    "\n",
    "# 3. Creating the extraction model with the features\n",
    "extractive_model = ClimateExtractiveModel(top_n=10)\n",
    "\n",
    "# 4. Training the BART model with the extraction model to create a hybrid text summarization engine\n",
    "abstractive_model = CLIMATEBart()\n",
    "\n",
    "# 5. Creating the hybrid model (ClimateCorpusCondenser)\n",
    "hybrid_model = C3(abstractive_model)\n",
    "\n",
    "# 6. Train the hybrid model\n",
    "hybrid_model.train(articles, summaries, extractive_model, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Save the hybrid model\n",
    "hybrid_model.save('C3_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. To use the model for summarization later:\n",
    "c3_model = C3(CLIMATEBart())\n",
    "c3_model.load('C3_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "new_article = \"Your climate change article text here...\"\n",
    "cleaned_article = preprocess_text(new_article)\n",
    "summary = c3_model.summarize(cleaned_article)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard BART Model (No Climate Corpus Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_model = BartModel.from_pretrained('facebook/bart-large')\n",
    "bart_tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_df = pd.read_csv('evaluation_corpuses.csv')\n",
    "eval_articles = evaluation_df['corpus'].tolist()\n",
    "reference_summaries = evaluation_df['summary'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c3_model = C3(CLIMATEBart())\n",
    "c3_model.load('C3_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BARTevaluator(c3_model, bart_model)\n",
    "\n",
    "c3_results, bart_results = evaluator.compare_models(eval_articles, reference_summaries)\n",
    "\n",
    "print(\"C3 Model Results:\")\n",
    "print(c3_results)\n",
    "print(\"\\nBART Model Results:\")\n",
    "print(bart_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.visualize_results(c3_results, bart_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c3_summaries = [c3_model.summarize(article) for article in tqdm(eval_articles, desc=\"Generating C3 summaries\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.generate_summary_wordcloud(c3_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.analyze_topic_coverage(eval_articles, c3_summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Hybrid Sentiment Analysis Network</h1></center>\n",
    "\n",
    "## RoBi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in training corpuses\n",
    "texts = normalized_df['corpus'].tolist()\n",
    "\n",
    "# Encode sentiment labels to numerical labels for training\n",
    "labels = normalized_df['sentiment'].map({\n",
    "    'Very Negative': 0, \n",
    "    'Negative': 1, \n",
    "    'Neutral': 2, \n",
    "    'Positive': 3, \n",
    "    'Very Positive': 4\n",
    "}).tolist()\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    texts, \n",
    "    labels, \n",
    "    test_size=0.2, \n",
    "    random_state=10\n",
    ")\n",
    "\n",
    "roberta_tokenizer = RobertaTokenizer.from_pretrained('roberta-large')\n",
    "\n",
    "train_dataset = SlidingWindow(\n",
    "    train_texts, \n",
    "    train_labels, \n",
    "    roberta_tokenizer, \n",
    "    config=SlidingWindowConfig()\n",
    ")\n",
    "val_dataset = SlidingWindow(\n",
    "    val_texts, \n",
    "    val_labels, \n",
    "    roberta_tokenizer, \n",
    "    config=SlidingWindowConfig()\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robi = RoBi(config=RoBiConfig())\n",
    "\n",
    "robi_train_config = TrainConfig(device=device)\n",
    "trained_robi = train_RoBi(\n",
    "    robi, \n",
    "    train_dataloader, \n",
    "    val_dataloader, \n",
    "    robi_train_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robi_save_config = SaveLoadConfig()\n",
    "save_RoBi(\n",
    "    trained_robi, \n",
    "    roberta_tokenizer, \n",
    "    robi_save_config\n",
    ")\n",
    "print(f\"Model and tokenizer saved successfully to {save_config.path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_config = SaveLoadConfig()  # Use default path from config\n",
    "loaded_model, loaded_tokenizer = load_RoBi(config=load_config, robi_config=RoBiConfig())\n",
    "print(f\"Model and tokenizer loaded successfully from {load_config.path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model.eval() is a kind of switch for some specific layers/parts of the model that behave differently during training and inference (evaluating) time. For example, Dropouts Layers, BatchNorm Layers etc. We need to turn them off during model evaluation, and .eval() will do it for us. In addition, the common practice for evaluating/validation is using torch.no_grad() in pair with model.eval() to turn off gradients computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict sentiment for new text\n",
    "new_text = \"This is a sample text for sentiment analysis.\"\n",
    "predict_config = PredictConfig()\n",
    "sentiment = predict_sentiment(\n",
    "    loaded_model, \n",
    "    loaded_tokenizer, \n",
    "    new_text, \n",
    "    device, \n",
    "    predict_config\n",
    ")\n",
    "\n",
    "print(f\"Predicted sentiment: {sentiment}\")\n",
    "# 0: Very Negative, 1: Negative, 2: Neutral, 3: Positive, 4: Very Positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pd.read_csv('path_to_your_evaluation_data.csv')\n",
    "print(eval_df.shape)\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h4>RoBi</h4></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robi_eval_config = RoBiEvaluationConfig()\n",
    "robi_predict_config = PredictConfig()\n",
    "\n",
    "print(\"Evaluating RoBi model...\")\n",
    "\n",
    "robi_model, robi_tokenizer = load_RoBi()\n",
    "robi_model.to(robi_eval_config.device)\n",
    "\n",
    "robi_preds, robi_true = evaluate_robi(\n",
    "    robi_model, \n",
    "    robi_tokenizer, \n",
    "    eval_df, \n",
    "    robi_eval_config.device, \n",
    "    robi_eval_config, \n",
    "    robi_predict_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robi_proba = []\n",
    "for _, row in eval_df.iterrows():\n",
    "    outputs = robi_model(\n",
    "        robi_tokenizer(\n",
    "            row['corpus'], \n",
    "            return_tensors=\"pt\", \n",
    "            truncation=True, \n",
    "            max_length=512, \n",
    "            padding=\"max_length\"\n",
    "        ).to(robi_eval_config.device))\n",
    "\n",
    "    probs = torch.softmax(outputs, dim=1)\n",
    "    robi_proba.append(probs.cpu().detach().numpy()[0])\n",
    "    \n",
    "robi_proba = np.array(robi_proba)\n",
    "\n",
    "evaluate_and_visualize(\n",
    "    robi_preds, \n",
    "    robi_true, \n",
    "    robi_proba, \n",
    "    \"RoBi\", \n",
    "    robi_eval_config.class_names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h4>Standard RoBERTa</h4></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nEvaluating standard RoBERTa model...\")\n",
    "\n",
    "# Load the pre-trained RoBERTa model and its tokenizer\n",
    "roberta_model = RobertaModel.from_pretrained(robi_eval_config.roberta_model_name)\n",
    "roberta_tokenizer = RobertaTokenizer.from_pretrained(robi_eval_config.roberta_model_name)\n",
    "roberta_model.to(robi_eval_config.device)\n",
    "\n",
    "# Evaluate RoBERTa\n",
    "roberta_preds, roberta_true = evaluate_roberta(\n",
    "    roberta_model, \n",
    "    roberta_tokenizer, \n",
    "    eval_df, \n",
    "    robi_eval_config.device, \n",
    "    robi_eval_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate probabilities for ROC curve (for RoBERTa)\n",
    "roberta_proba = []\n",
    "for _, row in eval_df.iterrows():\n",
    "    inputs = roberta_tokenizer(\n",
    "        row['corpus'], \n",
    "        return_tensors=\"pt\", \n",
    "        truncation=True, \n",
    "        max_length=512, \n",
    "        padding=\"max_length\"\n",
    "    ).to(robi_eval_config.device)\n",
    "    outputs = roberta_model(**inputs).last_hidden_state.mean(dim=1)\n",
    "    logits = torch.nn.Linear(\n",
    "        roberta_model.config.hidden_size, \n",
    "        robi_eval_config.num_classes\n",
    "    ).to(robi_eval_config.device)(outputs)\n",
    "    probs = torch.softmax(logits, dim=1)\n",
    "    roberta_proba.append(probs.cpu().detach().numpy()[0])\n",
    "\n",
    "roberta_proba = np.array(roberta_proba)\n",
    "\n",
    "# Visualize RoBERTa results\n",
    "evaluate_and_visualize(\n",
    "    roberta_preds, \n",
    "    roberta_true, \n",
    "    roberta_proba, \n",
    "    \"RoBERTa\", \n",
    "    robi_eval_config.class_names\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
